#!/usr/bin/env python3
"""
Mini-Wiki æ–‡æ¡£è´¨é‡æ£€æŸ¥è„šæœ¬
æ£€æŸ¥ç”Ÿæˆçš„æ–‡æ¡£æ˜¯å¦ç¬¦åˆ v3.0.2 è´¨é‡æ ‡å‡†
"""

import os
import re
import json
import argparse
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Optional
from datetime import datetime


@dataclass
class QualityMetrics:
    """å•ä¸ªæ–‡æ¡£çš„è´¨é‡æŒ‡æ ‡"""
    file_path: str
    line_count: int = 0
    section_count: int = 0  # H2 ç« èŠ‚æ•°
    subsection_count: int = 0  # H3 ç« èŠ‚æ•°
    diagram_count: int = 0  # Mermaid å›¾è¡¨æ•°
    class_diagram_count: int = 0  # classDiagram æ•°é‡
    code_example_count: int = 0  # ä»£ç ç¤ºä¾‹æ•°
    table_count: int = 0  # è¡¨æ ¼æ•°
    cross_link_count: int = 0  # äº¤å‰é“¾æ¥æ•°
    has_source_tracing: bool = False  # æ˜¯å¦æœ‰æºç è¿½æº¯
    has_best_practices: bool = False  # æ˜¯å¦æœ‰æœ€ä½³å®è·µç« èŠ‚
    has_performance: bool = False  # æ˜¯å¦æœ‰æ€§èƒ½ä¼˜åŒ–ç« èŠ‚
    has_troubleshooting: bool = False  # æ˜¯å¦æœ‰é”™è¯¯å¤„ç†/è°ƒè¯•ç« èŠ‚
    quality_level: str = "basic"  # basic / standard / professional
    issues: List[str] = field(default_factory=list)


@dataclass
class QualityReport:
    """è´¨é‡æ£€æŸ¥æŠ¥å‘Š"""
    wiki_path: str
    check_time: str
    total_docs: int = 0
    professional_count: int = 0
    standard_count: int = 0
    basic_count: int = 0
    docs: List[QualityMetrics] = field(default_factory=list)
    summary_issues: List[str] = field(default_factory=list)


def analyze_document(file_path: str) -> QualityMetrics:
    """åˆ†æå•ä¸ªæ–‡æ¡£çš„è´¨é‡"""
    metrics = QualityMetrics(file_path=file_path)
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
    except Exception as e:
        metrics.issues.append(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
        return metrics
    
    metrics.line_count = len(lines)
    
    # ç»Ÿè®¡ H2 ç« èŠ‚ (##)
    metrics.section_count = len(re.findall(r'^## ', content, re.MULTILINE))
    
    # ç»Ÿè®¡ H3 ç« èŠ‚ (###)
    metrics.subsection_count = len(re.findall(r'^### ', content, re.MULTILINE))
    
    # ç»Ÿè®¡ Mermaid å›¾è¡¨
    mermaid_blocks = re.findall(r'```mermaid[\s\S]*?```', content)
    metrics.diagram_count = len(mermaid_blocks)
    
    # ç»Ÿè®¡ classDiagram
    metrics.class_diagram_count = len(re.findall(r'classDiagram', content))
    
    # ç»Ÿè®¡ä»£ç ç¤ºä¾‹ (æ’é™¤ mermaid)
    all_code_blocks = re.findall(r'```(?!mermaid)[\s\S]*?```', content)
    metrics.code_example_count = len(all_code_blocks)
    
    # ç»Ÿè®¡è¡¨æ ¼
    metrics.table_count = len(re.findall(r'^\|.*\|$', content, re.MULTILINE)) // 2  # ä¼°ç®—
    
    # ç»Ÿè®¡äº¤å‰é“¾æ¥ (æ’é™¤å¤–éƒ¨é“¾æ¥)
    internal_links = re.findall(r'\[.*?\]\((?!http).*?\.md.*?\)', content)
    metrics.cross_link_count = len(internal_links)
    
    # æ£€æŸ¥æºç è¿½æº¯
    metrics.has_source_tracing = bool(
        re.search(r'\*\*Section sources\*\*|\*\*Diagram sources\*\*|file://', content)
    )
    
    # æ£€æŸ¥å…³é”®ç« èŠ‚
    content_lower = content.lower()
    metrics.has_best_practices = bool(
        re.search(r'æœ€ä½³å®è·µ|best practice', content_lower)
    )
    metrics.has_performance = bool(
        re.search(r'æ€§èƒ½ä¼˜åŒ–|æ€§èƒ½è€ƒé‡|performance', content_lower)
    )
    metrics.has_troubleshooting = bool(
        re.search(r'é”™è¯¯å¤„ç†|è°ƒè¯•|æ•…éšœæ’é™¤|troubleshoot|debug', content_lower)
    )
    
    # è¯„ä¼°è´¨é‡ç­‰çº§
    metrics.quality_level = evaluate_quality_level(metrics)
    
    # ç”Ÿæˆé—®é¢˜åˆ—è¡¨
    metrics.issues = generate_issues(metrics)
    
    return metrics


def evaluate_quality_level(m: QualityMetrics) -> str:
    """è¯„ä¼°è´¨é‡ç­‰çº§"""
    score = 0
    
    # è¡Œæ•°è¯„åˆ† (400+ ä¸ºä¸“ä¸šçº§)
    if m.line_count >= 400:
        score += 3
    elif m.line_count >= 250:
        score += 2
    elif m.line_count >= 150:
        score += 1
    
    # ç« èŠ‚æ•°è¯„åˆ†
    if m.section_count >= 12:
        score += 3
    elif m.section_count >= 8:
        score += 2
    elif m.section_count >= 5:
        score += 1
    
    # å›¾è¡¨è¯„åˆ†
    if m.diagram_count >= 3:
        score += 3
    elif m.diagram_count >= 2:
        score += 2
    elif m.diagram_count >= 1:
        score += 1
    
    # classDiagram è¯„åˆ†
    if m.class_diagram_count >= 1:
        score += 2
    
    # ä»£ç ç¤ºä¾‹è¯„åˆ†
    if m.code_example_count >= 5:
        score += 3
    elif m.code_example_count >= 3:
        score += 2
    elif m.code_example_count >= 1:
        score += 1
    
    # æºç è¿½æº¯è¯„åˆ†
    if m.has_source_tracing:
        score += 2
    
    # å…³é”®ç« èŠ‚è¯„åˆ†
    if m.has_best_practices:
        score += 1
    if m.has_performance:
        score += 1
    if m.has_troubleshooting:
        score += 1
    
    # æœ€ç»ˆè¯„çº§
    if score >= 15:
        return "professional"
    elif score >= 8:
        return "standard"
    else:
        return "basic"


def calculate_expected_metrics(file_path: str) -> Dict[str, int]:
    """åŸºäºæ¨¡å—å¤æ‚åº¦åŠ¨æ€è®¡ç®—æœŸæœ›æŒ‡æ ‡"""
    # é»˜è®¤æœŸæœ›å€¼ï¼ˆç”¨äºæ— æ³•åˆ†ææºç çš„æƒ…å†µï¼‰
    expected = {
        "min_lines": 100,
        "min_sections": 6,
        "min_diagrams": 1,
        "min_examples": 2,
    }
    
    # å°è¯•æ¨æ–­æ¨¡å—å¤æ‚åº¦
    file_name = os.path.basename(file_path).replace('.md', '')
    
    # æ ¸å¿ƒæ¨¡å—æ£€æµ‹
    core_keywords = ['core', 'agent', 'editor', 'store', 'main', 'client']
    is_core = any(kw in file_name.lower() for kw in core_keywords)
    
    # å·¥å…·/é…ç½®æ¨¡å—æ£€æµ‹
    util_keywords = ['util', 'helper', 'common', 'shared', 'constant', 'config', 'type']
    is_util = any(kw in file_name.lower() for kw in util_keywords)
    
    # ç´¢å¼•æ–‡ä»¶æ£€æµ‹
    is_index = file_name in ['index', '_index', 'TOC', 'doc-map']
    
    if is_core:
        expected["min_lines"] = 200
        expected["min_sections"] = 8
        expected["min_diagrams"] = 2
        expected["min_examples"] = 3
    elif is_util:
        expected["min_lines"] = 80
        expected["min_sections"] = 5
        expected["min_diagrams"] = 1
        expected["min_examples"] = 2
    elif is_index:
        expected["min_lines"] = 50
        expected["min_sections"] = 3
        expected["min_diagrams"] = 1
        expected["min_examples"] = 0
    
    return expected


def generate_issues(m: QualityMetrics) -> List[str]:
    """ç”Ÿæˆé—®é¢˜åˆ—è¡¨ï¼ˆåŸºäºåŠ¨æ€æœŸæœ›å€¼ï¼‰"""
    issues = []
    
    # åŠ¨æ€è®¡ç®—æœŸæœ›æŒ‡æ ‡
    expected = calculate_expected_metrics(m.file_path)
    
    # åŸºäºåŠ¨æ€æœŸæœ›å€¼æ£€æŸ¥
    if m.line_count < expected["min_lines"]:
        issues.append(f"è¡Œæ•°ä¸è¶³: {m.line_count}/{expected['min_lines']} (åŸºäºæ¨¡å—å¤æ‚åº¦)")
    
    if m.section_count < expected["min_sections"]:
        issues.append(f"ç« èŠ‚æ•°ä¸è¶³: {m.section_count}/{expected['min_sections']}")
    
    if m.diagram_count < expected["min_diagrams"]:
        issues.append(f"å›¾è¡¨æ•°ä¸è¶³: {m.diagram_count}/{expected['min_diagrams']}")
    
    if m.class_diagram_count < 1 and expected["min_diagrams"] >= 2:
        issues.append("æ ¸å¿ƒæ¨¡å—ç¼ºå°‘ classDiagram ç±»å›¾")
    
    if m.code_example_count < expected["min_examples"]:
        issues.append(f"ä»£ç ç¤ºä¾‹ä¸è¶³: {m.code_example_count}/{expected['min_examples']}")
    
    if not m.has_source_tracing and expected["min_lines"] >= 150:
        issues.append("ç¼ºå°‘æºç è¿½æº¯ (Section sources)")
    
    # æ ¸å¿ƒæ¨¡å—éœ€è¦æ›´å¤šç« èŠ‚
    if expected["min_sections"] >= 8:
        if not m.has_best_practices:
            issues.append("æ ¸å¿ƒæ¨¡å—ç¼ºå°‘ã€Œæœ€ä½³å®è·µã€ç« èŠ‚")
        if not m.has_performance:
            issues.append("æ ¸å¿ƒæ¨¡å—ç¼ºå°‘ã€Œæ€§èƒ½ä¼˜åŒ–ã€ç« èŠ‚")
        if not m.has_troubleshooting:
            issues.append("æ ¸å¿ƒæ¨¡å—ç¼ºå°‘ã€Œé”™è¯¯å¤„ç†ã€ç« èŠ‚")
    
    if m.cross_link_count < 1:
        issues.append("ç¼ºå°‘ç›¸å…³æ–‡æ¡£äº¤å‰é“¾æ¥")
    
    return issues


def check_wiki_quality(wiki_path: str) -> QualityReport:
    """æ£€æŸ¥æ•´ä¸ª Wiki ç›®å½•çš„è´¨é‡"""
    report = QualityReport(
        wiki_path=wiki_path,
        check_time=datetime.now().isoformat()
    )
    
    wiki_dir = Path(wiki_path) / "wiki"
    if not wiki_dir.exists():
        report.summary_issues.append(f"Wiki ç›®å½•ä¸å­˜åœ¨: {wiki_dir}")
        return report
    
    # éå†æ‰€æœ‰ .md æ–‡ä»¶
    for md_file in wiki_dir.rglob("*.md"):
        metrics = analyze_document(str(md_file))
        report.docs.append(metrics)
        report.total_docs += 1
        
        if metrics.quality_level == "professional":
            report.professional_count += 1
        elif metrics.quality_level == "standard":
            report.standard_count += 1
        else:
            report.basic_count += 1
    
    return report


def print_report(report: QualityReport, verbose: bool = False):
    """æ‰“å°è´¨é‡æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“Š Mini-Wiki æ–‡æ¡£è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 60)
    print(f"ğŸ“ Wiki è·¯å¾„: {report.wiki_path}")
    print(f"ğŸ• æ£€æŸ¥æ—¶é—´: {report.check_time}")
    print()
    
    # æ€»ä½“ç»Ÿè®¡
    print("## ğŸ“ˆ æ€»ä½“ç»Ÿè®¡\n")
    print(f"| æŒ‡æ ‡ | æ•°å€¼ |")
    print(f"|------|------|")
    print(f"| æ–‡æ¡£æ€»æ•° | {report.total_docs} |")
    print(f"| ğŸŸ¢ Professional | {report.professional_count} ({report.professional_count/max(1,report.total_docs)*100:.1f}%) |")
    print(f"| ğŸŸ¡ Standard | {report.standard_count} ({report.standard_count/max(1,report.total_docs)*100:.1f}%) |")
    print(f"| ğŸ”´ Basic | {report.basic_count} ({report.basic_count/max(1,report.total_docs)*100:.1f}%) |")
    print()
    
    # éœ€è¦æ”¹è¿›çš„æ–‡æ¡£
    basic_docs = [d for d in report.docs if d.quality_level == "basic"]
    standard_docs = [d for d in report.docs if d.quality_level == "standard"]
    
    if basic_docs:
        print("## ğŸ”´ éœ€è¦å‡çº§çš„æ–‡æ¡£ (Basic)\n")
        print("| æ–‡æ¡£ | è¡Œæ•° | ç« èŠ‚ | å›¾è¡¨ | é—®é¢˜æ•° |")
        print("|------|------|------|------|--------|")
        for doc in basic_docs:
            rel_path = os.path.basename(doc.file_path)
            print(f"| {rel_path} | {doc.line_count} | {doc.section_count} | {doc.diagram_count} | {len(doc.issues)} |")
        print()
    
    if standard_docs:
        print("## ğŸŸ¡ å¯ä¼˜åŒ–çš„æ–‡æ¡£ (Standard)\n")
        print("| æ–‡æ¡£ | è¡Œæ•° | ç« èŠ‚ | å›¾è¡¨ | é—®é¢˜æ•° |")
        print("|------|------|------|------|--------|")
        for doc in standard_docs:
            rel_path = os.path.basename(doc.file_path)
            print(f"| {rel_path} | {doc.line_count} | {doc.section_count} | {doc.diagram_count} | {len(doc.issues)} |")
        print()
    
    # è¯¦ç»†é—®é¢˜åˆ—è¡¨
    if verbose:
        print("## ğŸ“‹ è¯¦ç»†é—®é¢˜åˆ—è¡¨\n")
        for doc in report.docs:
            if doc.issues:
                rel_path = os.path.relpath(doc.file_path, report.wiki_path)
                print(f"### {rel_path} [{doc.quality_level.upper()}]\n")
                for issue in doc.issues:
                    print(f"- âš ï¸ {issue}")
                print()
    
    # æ”¹è¿›å»ºè®®
    print("## ğŸ’¡ æ”¹è¿›å»ºè®®\n")
    if report.basic_count > 0:
        print(f"- è¿è¡Œ `å‡çº§ wiki` å‘½ä»¤å‡çº§ {report.basic_count} ä¸ª Basic çº§æ–‡æ¡£")
    if not any(d.has_source_tracing for d in report.docs):
        print("- æ·»åŠ æºç è¿½æº¯ (Section sources / Diagram sources)")
    if not any(d.class_diagram_count > 0 for d in report.docs):
        print("- ä¸ºæ ¸å¿ƒç±»æ·»åŠ  classDiagram ç±»å›¾")
    
    print()
    print("=" * 60)
    
    # è¿”å›é€€å‡ºç 
    if report.basic_count > report.total_docs * 0.5:
        return 2  # è¶…è¿‡50%æ˜¯ basicï¼Œä¸¥é‡
    elif report.basic_count > 0:
        return 1  # æœ‰ basic æ–‡æ¡£ï¼Œè­¦å‘Š
    else:
        return 0  # å…¨éƒ¨è¾¾æ ‡


def save_report_json(report: QualityReport, output_path: str):
    """ä¿å­˜æŠ¥å‘Šä¸º JSON"""
    data = {
        "wiki_path": report.wiki_path,
        "check_time": report.check_time,
        "summary": {
            "total": report.total_docs,
            "professional": report.professional_count,
            "standard": report.standard_count,
            "basic": report.basic_count
        },
        "docs": []
    }
    
    for doc in report.docs:
        data["docs"].append({
            "file": doc.file_path,
            "metrics": {
                "lines": doc.line_count,
                "sections": doc.section_count,
                "diagrams": doc.diagram_count,
                "class_diagrams": doc.class_diagram_count,
                "code_examples": doc.code_example_count,
                "tables": doc.table_count,
                "cross_links": doc.cross_link_count,
                "has_source_tracing": doc.has_source_tracing,
                "has_best_practices": doc.has_best_practices,
                "has_performance": doc.has_performance,
                "has_troubleshooting": doc.has_troubleshooting
            },
            "quality_level": doc.quality_level,
            "issues": doc.issues
        })
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Mini-Wiki æ–‡æ¡£è´¨é‡æ£€æŸ¥å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python check_quality.py /path/to/project/.mini-wiki
  python check_quality.py . --verbose
  python check_quality.py . --json report.json
        """
    )
    parser.add_argument(
        "wiki_path",
        nargs="?",
        default=".mini-wiki",
        help="Wiki ç›®å½•è·¯å¾„ (é»˜è®¤: .mini-wiki)"
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†é—®é¢˜åˆ—è¡¨"
    )
    parser.add_argument(
        "--json",
        metavar="FILE",
        help="å°†æŠ¥å‘Šä¿å­˜ä¸º JSON æ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è·¯å¾„
    wiki_path = args.wiki_path
    if not os.path.exists(wiki_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {wiki_path}")
        return 1
    
    # æ‰§è¡Œæ£€æŸ¥
    report = check_wiki_quality(wiki_path)
    
    # æ‰“å°æŠ¥å‘Š
    exit_code = print_report(report, verbose=args.verbose)
    
    # ä¿å­˜ JSON
    if args.json:
        save_report_json(report, args.json)
    
    return exit_code


if __name__ == "__main__":
    exit(main())
